{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Residual_attention_network_with_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEmLReKtqkJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split(img):\n",
        "  img=img\n",
        "  # labels.append(label)\n",
        "  #print(img.shape)\n",
        "  n,c,h,w=img.shape\n",
        "  # print(len(img))\n",
        "  #print(img.shape)\n",
        "  left_lung=img[:,:,0:h,0:int(w/2)]\n",
        "  right_lung=img[:,:,0:h,int(w/2):w]\n",
        "  #print(left_lung.shape)\n",
        "  #print(right_lung.shape)             \n",
        "  #trans1=transforms.ToTensor()\n",
        "  #left_lung=trans1(left_lung)\n",
        "  #right_lung=trans1(right_lung)\n",
        "  # left_lung=pad_to_square(left_lung)\n",
        "  # right_lung=pad_to_square(right_lung)\n",
        "  # #print(left_lung.shape)\n",
        "  # #print(right_lung.shape)\n",
        "  # train_left.append(left_lung)\n",
        "  # train_right.append(right_lung)\n",
        "  # print(left_lung.shape)\n",
        "  return left_lung, right_lung"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5MYeLh7UapZ",
        "colab_type": "code",
        "outputId": "012445d8-63e8-4d3a-b527-86a26c878587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwkle2nT7Mb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "pathimg='/content/drive/My Drive/cropped_images_new/'\n",
        "image_path=os.listdir(pathimg)\n",
        "\n",
        "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# normalize = transforms.Normalize([0.5742, 0.5745, 0.5749], [0.1908, 0.1907, 0.1906])\n",
        "transform = transforms.Compose([\n",
        "    # transforms.RandomResizedCrop((448,224)),   #left, top, right, bottom\n",
        "    # transforms.Resize((448,224)),\n",
        "    transforms.Resize((448,448)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "for files in image_path:\n",
        "  img=Image.open(pathimg + files).convert('RGB')\n",
        "  # print(np.array(img))\n",
        "  print(\"######\")\n",
        "\n",
        "  # img1=np.array(img)/255\n",
        "  # img1=torch.tensor(img)\n",
        "  newimg=transform(img)\n",
        "  # print(newimg.shape)\n",
        "  # left,right=split(newimg)\n",
        "  # print(img1)\n",
        "  # plt.imshow(newimg)\n",
        "  plt.imshow(newimg.permute(1, 2, 0))\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4FOBzz8uFQn",
        "colab_type": "code",
        "outputId": "28c0308a-fa39-4045-ef80-a83387b13d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from DatasetGenerator import DatasetGenerator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "def online_mean_and_sd(loader):\n",
        "    \"\"\"Compute the mean and sd in an online fashion\n",
        "\n",
        "        Var[x] = E[X^2] - E^2[X]\n",
        "    \"\"\"\n",
        "    cnt = 0\n",
        "    fst_moment = torch.empty(3)\n",
        "    snd_moment = torch.empty(3)\n",
        "\n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "\n",
        "        b, c, h, w = images.shape\n",
        "        nb_pixels = b * h * w\n",
        "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
        "        sum_of_square = torch.sum(images ** 2, dim=[0, 2, 3])\n",
        "        fst_moment = (cnt * fst_moment + sum_) / (cnt + nb_pixels)\n",
        "        snd_moment = (cnt * snd_moment + sum_of_square) / (cnt + nb_pixels)\n",
        "\n",
        "        cnt += nb_pixels\n",
        "\n",
        "    return fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)\n",
        "\n",
        "   \n",
        "transform = transforms.Compose([\n",
        "    # transforms.RandomResizedCrop((448,224)),   #left, top, right, bottom\n",
        "    transforms.Resize((448,224)),\n",
        "    transforms.ToTensor()\n",
        "    # normalize\n",
        "])\n",
        "pathDirData='/content/drive/My Drive/'\n",
        "dataset = DatasetGenerator(pathImageDirectory=pathDirData, transform=transform)\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    num_workers=1,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "mean, std = online_mean_and_sd(loader)\n",
        "\n",
        "print(\"mean: \",mean)\n",
        "print(\"std: \",std)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean:  tensor([0.5742, 0.5745, 0.5749])\n",
            "std:  tensor([0.1908, 0.1907, 0.1906])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4uQyoic5tNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "def pad_to_square(img, pad_value=0):\n",
        "    n,c,h, w = img.shape\n",
        "    dim_diff = np.abs(h - w)\n",
        "    # (upper / left) padding and (lower / right) padding\n",
        "    pad1, pad2 = dim_diff // 2, dim_diff - dim_diff // 2\n",
        "    # Determine padding\n",
        "    pad = (0, 0, pad1, pad2) if h <= w else (pad1, pad2, 0, 0)\n",
        "    # Add padding\n",
        "    img = F.pad(img, pad, \"constant\", value=pad_value)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXLIyli8tkQM",
        "colab_type": "code",
        "outputId": "60233aca-8157-49af-bc45-9b771b71bd8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from DatasetGenerator import DatasetGenerator\n",
        "# from model.residual_attention_network_pre import ResidualAttentionModel\n",
        "# based https://github.com/liudaizong/Residual-Attention-Network\n",
        "from residual_attention_network import ResidualAttentionModel_448input as ResidualAttentionModel\n",
        "\n",
        "model_file = '/content/model_448_sgd_full_lungs_normalise4.pkl'\n",
        "\n",
        "\n",
        "# for test\n",
        "def test(model, test_loader, btrain=False, model_file=model_file):\n",
        "    # Test\n",
        "    if not btrain:\n",
        "        model.load_state_dict(torch.load(model_file))\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    #\n",
        "    class_correct = list(0. for i in range(2))\n",
        "    class_total = list(0. for i in range(2))\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        # left,right=split(images)\n",
        "        # left = Variable(left.cuda())\n",
        "        # labels = Variable(labels.cuda())\n",
        "        images = Variable(images.cuda())\n",
        "        labels = Variable(labels.cuda())\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.data).sum()\n",
        "        #\n",
        "        c = (predicted == labels.data).squeeze()\n",
        "        # print(labels)\n",
        "        # print(c.shape)\n",
        "        # print(c)\n",
        "        xyz=c.to('cpu').numpy()\n",
        "        # print(\"xyz: \" ,xyz[2])\n",
        "        for i in range(2):\n",
        "            label = labels.data[i]\n",
        "            # print(c[i])\n",
        "            # abc=c[i][0]\n",
        "            class_correct[label] += xyz[i]\n",
        "            class_total[label] += 1\n",
        "        #     print(xyz[i])\n",
        "        #     print(\"class_correct: \",class_correct)\n",
        "        # print(\"batch end\")\n",
        "\n",
        "    print('Accuracy of the model on the test images: %d %%' % (100 * float(correct) / total))\n",
        "    print('Accuracy of the model on the test images:', float(correct)/total)\n",
        "    for i in range(2):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    return 100*correct / total\n",
        "\n",
        "\n",
        "# Image Preprocessing\n",
        "pathDirData='/content/drive/My Drive/'\n",
        "pathDirDatatest='/content/drive/My Drive/test/'\n",
        "# normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# normalize = transforms.Normalize([0.5742, 0.5745, 0.5749], [0.1908, 0.1907, 0.1906])\n",
        "transform = transforms.Compose([\n",
        "    # transforms.RandomRotation(degrees=15),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.Resize((224,448)),   #left, top, right, bottom\n",
        "    transforms.Resize((448,448)),\n",
        "    # transforms.Scale(224),\n",
        "    transforms.ToTensor()\n",
        "    # normalize\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    # transforms.Resize((224,448)),\n",
        "    transforms.Resize((448,448)),                                  \n",
        "    transforms.ToTensor()\n",
        "    # normalize\n",
        "])\n",
        "# when image is rgb, totensor do the division 255\n",
        "\n",
        "train_dataset = DatasetGenerator(pathImageDirectory=pathDirData, transform=transform)\n",
        "\n",
        "test_dataset = DatasetGenerator(pathImageDirectory=pathDirDatatest, transform=test_transform)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=6, # 64\n",
        "                                           shuffle=True, num_workers=8)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=2,\n",
        "                                          shuffle=True)\n",
        "\n",
        "classes = ('no Roi','Roi')\n",
        "model = ResidualAttentionModel().cuda()\n",
        "# print(model)\n",
        "\n",
        "lr = 3.000002e-04  # 0.1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.7, nesterov=True, weight_decay=0.0001)\n",
        "# optimizer = optim.Adam (model.parameters(), lr=lr, betas=(0.8, 0.999), eps=1e-08, weight_decay=0.0001)\n",
        "# scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 4, mode = 'min')\n",
        "is_train = True\n",
        "is_pretrain = True\n",
        "acc_best = 0\n",
        "total_epoch = 30\n",
        "if is_train is True:\n",
        "    if is_pretrain == True:\n",
        "        model.load_state_dict((torch.load(model_file)))\n",
        "    # Training\n",
        "    for epoch in range(total_epoch):\n",
        "        model.train()\n",
        "        tims = time.time()\n",
        "        lossavg=0\n",
        "        tot=0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            # print(images.shape)\n",
        "            # left,right=split(images)\n",
        "            # print(left.shape)\n",
        "            images = Variable(images.cuda())\n",
        "            # left = Variable(left.cuda())\n",
        "            # print(images.data)\n",
        "            # print(labels)\n",
        "            labels = Variable(labels.cuda())\n",
        "\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # print(\"hello\")\n",
        "            lossavg +=loss.item()\n",
        "            tot+=1\n",
        "            \n",
        "            # if (i+1) % 10 == 0:\n",
        "                # print(\"Epoch [%d/%d], Iter [%d/%d] Loss: %.4f\" %(epoch+1, total_epoch, i+1, len(train_loader), loss.item()))\n",
        "        \n",
        "        aver=lossavg/tot\n",
        "        print(\" \")\n",
        "        print(\" \")\n",
        "        print(\" \")\n",
        "        print('the epoch takes time:',time.time()-tims)\n",
        "        print(\"Epoch [%d/%d],  AVERAGELoss: %.4f\" %(epoch+1,total_epoch,aver))\n",
        "        print('evaluate test set:')\n",
        "        acc = test(model, test_loader, btrain=True)\n",
        "        # print(\"acc\",acc)\n",
        "        # print(acc_best)\n",
        "        if acc > acc_best:\n",
        "            acc_best = acc\n",
        "            print('current best acc,', acc_best)\n",
        "            torch.save(model.state_dict(), \"/content/model_448_sgd_full_lungs_normalise3.pkl\")\n",
        "        # Decaying Learning Rate\n",
        "        if (epoch+1) / float(total_epoch) == 0.3 or (epoch+1) / float(total_epoch) == 0.6 or (epoch+1) / float(total_epoch) == 0.9:\n",
        "            lr /= 10\n",
        "            print('reset learning rate to:', lr)\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "                print(param_group['lr'])\n",
        "            # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "            # optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
        "    # Save the Model\n",
        "    torch.save(model.state_dict(), 'last_model_448_sgd_full_lungs.pkl')\n",
        "\n",
        "else:\n",
        "    test(model, test_loader, btrain=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.39883875846863\n",
            "Epoch [1/30],  AVERAGELoss: 0.1038\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 75 %\n",
            "Accuracy of the model on the test images: 0.75\n",
            "Accuracy of no Roi : 80 %\n",
            "Accuracy of   Roi : 71 %\n",
            "current best acc, tensor(75, device='cuda:0')\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.767815589904785\n",
            "Epoch [2/30],  AVERAGELoss: 0.1332\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 81 %\n",
            "Accuracy of the model on the test images: 0.8125\n",
            "Accuracy of no Roi : 80 %\n",
            "Accuracy of   Roi : 82 %\n",
            "current best acc, tensor(81, device='cuda:0')\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.895832538604736\n",
            "Epoch [3/30],  AVERAGELoss: 0.1208\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 75 %\n",
            "Accuracy of the model on the test images: 0.75\n",
            "Accuracy of no Roi : 80 %\n",
            "Accuracy of   Roi : 71 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.81701970100403\n",
            "Epoch [4/30],  AVERAGELoss: 0.1111\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 77 %\n",
            "Accuracy of the model on the test images: 0.7708333333333334\n",
            "Accuracy of no Roi : 80 %\n",
            "Accuracy of   Roi : 75 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.647310733795166\n",
            "Epoch [5/30],  AVERAGELoss: 0.1024\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 81 %\n",
            "Accuracy of the model on the test images: 0.8125\n",
            "Accuracy of no Roi : 85 %\n",
            "Accuracy of   Roi : 78 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.97775149345398\n",
            "Epoch [6/30],  AVERAGELoss: 0.1216\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 81 %\n",
            "Accuracy of the model on the test images: 0.8125\n",
            "Accuracy of no Roi : 75 %\n",
            "Accuracy of   Roi : 85 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.09799408912659\n",
            "Epoch [7/30],  AVERAGELoss: 0.0720\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 81 %\n",
            "Accuracy of the model on the test images: 0.8125\n",
            "Accuracy of no Roi : 80 %\n",
            "Accuracy of   Roi : 82 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.51244902610779\n",
            "Epoch [8/30],  AVERAGELoss: 0.1007\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 79 %\n",
            "Accuracy of the model on the test images: 0.7916666666666666\n",
            "Accuracy of no Roi : 80 %\n",
            "Accuracy of   Roi : 78 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.79509425163269\n",
            "Epoch [9/30],  AVERAGELoss: 0.0808\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 77 %\n",
            "Accuracy of the model on the test images: 0.7708333333333334\n",
            "Accuracy of no Roi : 75 %\n",
            "Accuracy of   Roi : 78 %\n",
            "reset learning rate to: 3.000002e-05\n",
            "3.000002e-05\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.02555227279663\n",
            "Epoch [10/30],  AVERAGELoss: 0.0677\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 79 %\n",
            "Accuracy of the model on the test images: 0.7916666666666666\n",
            "Accuracy of no Roi : 90 %\n",
            "Accuracy of   Roi : 71 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.03749179840088\n",
            "Epoch [11/30],  AVERAGELoss: 0.1440\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 79 %\n",
            "Accuracy of the model on the test images: 0.7916666666666666\n",
            "Accuracy of no Roi : 65 %\n",
            "Accuracy of   Roi : 89 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.54485869407654\n",
            "Epoch [12/30],  AVERAGELoss: 0.1029\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 79 %\n",
            "Accuracy of the model on the test images: 0.7916666666666666\n",
            "Accuracy of no Roi : 70 %\n",
            "Accuracy of   Roi : 85 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.18819284439087\n",
            "Epoch [13/30],  AVERAGELoss: 0.0994\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 79 %\n",
            "Accuracy of the model on the test images: 0.7916666666666666\n",
            "Accuracy of no Roi : 65 %\n",
            "Accuracy of   Roi : 89 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.20553946495056\n",
            "Epoch [14/30],  AVERAGELoss: 0.0936\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 83 %\n",
            "Accuracy of the model on the test images: 0.8333333333333334\n",
            "Accuracy of no Roi : 80 %\n",
            "Accuracy of   Roi : 85 %\n",
            "current best acc, tensor(83, device='cuda:0')\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.786545515060425\n",
            "Epoch [15/30],  AVERAGELoss: 0.0724\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 81 %\n",
            "Accuracy of the model on the test images: 0.8125\n",
            "Accuracy of no Roi : 75 %\n",
            "Accuracy of   Roi : 85 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.14207315444946\n",
            "Epoch [16/30],  AVERAGELoss: 0.0702\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 83 %\n",
            "Accuracy of the model on the test images: 0.8333333333333334\n",
            "Accuracy of no Roi : 80 %\n",
            "Accuracy of   Roi : 85 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.238215923309326\n",
            "Epoch [17/30],  AVERAGELoss: 0.0851\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 83 %\n",
            "Accuracy of the model on the test images: 0.8333333333333334\n",
            "Accuracy of no Roi : 90 %\n",
            "Accuracy of   Roi : 78 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.540104389190674\n",
            "Epoch [18/30],  AVERAGELoss: 0.0663\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 77 %\n",
            "Accuracy of the model on the test images: 0.7708333333333334\n",
            "Accuracy of no Roi : 85 %\n",
            "Accuracy of   Roi : 71 %\n",
            "reset learning rate to: 3.0000019999999997e-06\n",
            "3.0000019999999997e-06\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.29405927658081\n",
            "Epoch [19/30],  AVERAGELoss: 0.0372\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 77 %\n",
            "Accuracy of the model on the test images: 0.7708333333333334\n",
            "Accuracy of no Roi : 75 %\n",
            "Accuracy of   Roi : 78 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 52.20099902153015\n",
            "Epoch [20/30],  AVERAGELoss: 0.0717\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 81 %\n",
            "Accuracy of the model on the test images: 0.8125\n",
            "Accuracy of no Roi : 85 %\n",
            "Accuracy of   Roi : 78 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.56451368331909\n",
            "Epoch [21/30],  AVERAGELoss: 0.1004\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 79 %\n",
            "Accuracy of the model on the test images: 0.7916666666666666\n",
            "Accuracy of no Roi : 75 %\n",
            "Accuracy of   Roi : 82 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.45668172836304\n",
            "Epoch [22/30],  AVERAGELoss: 0.0719\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 79 %\n",
            "Accuracy of the model on the test images: 0.7916666666666666\n",
            "Accuracy of no Roi : 85 %\n",
            "Accuracy of   Roi : 75 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.26161241531372\n",
            "Epoch [23/30],  AVERAGELoss: 0.0861\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 81 %\n",
            "Accuracy of the model on the test images: 0.8125\n",
            "Accuracy of no Roi : 75 %\n",
            "Accuracy of   Roi : 85 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.234843492507935\n",
            "Epoch [24/30],  AVERAGELoss: 0.0888\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 77 %\n",
            "Accuracy of the model on the test images: 0.7708333333333334\n",
            "Accuracy of no Roi : 85 %\n",
            "Accuracy of   Roi : 71 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.816999673843384\n",
            "Epoch [25/30],  AVERAGELoss: 0.0633\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 85 %\n",
            "Accuracy of the model on the test images: 0.8541666666666666\n",
            "Accuracy of no Roi : 85 %\n",
            "Accuracy of   Roi : 85 %\n",
            "current best acc, tensor(85, device='cuda:0')\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.542574405670166\n",
            "Epoch [26/30],  AVERAGELoss: 0.1001\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 77 %\n",
            "Accuracy of the model on the test images: 0.7708333333333334\n",
            "Accuracy of no Roi : 80 %\n",
            "Accuracy of   Roi : 75 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.50210094451904\n",
            "Epoch [27/30],  AVERAGELoss: 0.0850\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 77 %\n",
            "Accuracy of the model on the test images: 0.7708333333333334\n",
            "Accuracy of no Roi : 90 %\n",
            "Accuracy of   Roi : 67 %\n",
            "reset learning rate to: 3.0000019999999997e-07\n",
            "3.0000019999999997e-07\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.63617420196533\n",
            "Epoch [28/30],  AVERAGELoss: 0.0588\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 77 %\n",
            "Accuracy of the model on the test images: 0.7708333333333334\n",
            "Accuracy of no Roi : 75 %\n",
            "Accuracy of   Roi : 78 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.67902088165283\n",
            "Epoch [29/30],  AVERAGELoss: 0.0808\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 79 %\n",
            "Accuracy of the model on the test images: 0.7916666666666666\n",
            "Accuracy of no Roi : 70 %\n",
            "Accuracy of   Roi : 85 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 51.466935873031616\n",
            "Epoch [30/30],  AVERAGELoss: 0.0660\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 83 %\n",
            "Accuracy of the model on the test images: 0.8333333333333334\n",
            "Accuracy of no Roi : 90 %\n",
            "Accuracy of   Roi : 78 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kU2Z3I5vHNd",
        "colab_type": "code",
        "outputId": "67451f12-6b06-47cb-d9da-85e984b8b2aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "############Right lung\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from DatasetGenerator import DatasetGenerator\n",
        "# from model.residual_attention_network_pre import ResidualAttentionModel\n",
        "# based https://github.com/liudaizong/Residual-Attention-Network\n",
        "from residual_attention_network import ResidualAttentionModel_448input as ResidualAttentionModel\n",
        "\n",
        "model_file = './model_92_sgd2_left.pkl'\n",
        "\n",
        "\n",
        "# for test\n",
        "def test(model, test_loader, btrain=False, model_file=model_file):\n",
        "    # Test\n",
        "    if not btrain:\n",
        "        model.load_state_dict(torch.load(model_file))\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    #\n",
        "    class_correct = list(0. for i in range(2))\n",
        "    class_total = list(0. for i in range(2))\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        left,right=split(images)\n",
        "        left = Variable(left.cuda())\n",
        "        labels = Variable(labels.cuda())\n",
        "        outputs = model(left)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.data).sum()\n",
        "        #\n",
        "        c = (predicted == labels.data).squeeze()\n",
        "        # print(labels)\n",
        "        # print(c.shape)\n",
        "        # print(c)\n",
        "        xyz=c.to('cpu').numpy()\n",
        "        # print(\"xyz: \" ,xyz[2])\n",
        "        \n",
        "        for i in range(2):\n",
        "            label = labels.data[i]\n",
        "            # print(c[i])\n",
        "            # abc=c[i][0]\n",
        "            class_correct[label] += xyz[i]\n",
        "            class_total[label] += 1\n",
        "        #     print(xyz[i])\n",
        "        #     print(\"class_correct: \",class_correct)\n",
        "        # print(\"batch end\")\n",
        "\n",
        "    print('Accuracy of the model on the test images: %d %%' % (100 * float(correct) / total))\n",
        "    print('Accuracy of the model on the test images:', float(correct)/total)\n",
        "    for i in range(2):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    return 100*correct / total\n",
        "\n",
        "\n",
        "# Image Preprocessing\n",
        "pathDirData='/content/drive/My Drive/'\n",
        "pathDirDataTest='/content/drive/My Drive/test/'\n",
        "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# normalize = transforms.Normalize([0.5742, 0.5745, 0.5749], [0.1908, 0.1907, 0.1906])\n",
        "transform = transforms.Compose([\n",
        "    # transforms.RandomRotation(degrees=15),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize((448,896)),   #left, top, right, bottom\n",
        "    # transforms.Scale(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((448,896)),                                  \n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "# when image is rgb, totensor do the division 255\n",
        "\n",
        "train_dataset = DatasetGenerator(pathImageDirectory=pathDirData, transform=transform)\n",
        "\n",
        "test_dataset = DatasetGenerator(pathImageDirectory=pathDirDataTest, transform=test_transform)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=6, # 64\n",
        "                                           shuffle=True, num_workers=8)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=2,\n",
        "                                          shuffle=True)\n",
        "\n",
        "classes = ('no Roi','Roi')\n",
        "model = ResidualAttentionModel().cuda()\n",
        "# print(model)\n",
        "\n",
        "lr = 1.000002e-04  # 0.1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
        "# optimizer = optim.Adam (model.parameters(), lr=lr, betas=(0.8, 0.999), eps=1e-08, weight_decay=0.0001)\n",
        "# scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 4, mode = 'min')\n",
        "is_train = True\n",
        "is_pretrain = False\n",
        "acc_best = 0\n",
        "total_epoch = 50\n",
        "if is_train is True:\n",
        "    if is_pretrain == True:\n",
        "        model.load_state_dict((torch.load(model_file)))\n",
        "    # Training\n",
        "    for epoch in range(total_epoch):\n",
        "        model.train()\n",
        "        tims = time.time()\n",
        "        lossavg=0\n",
        "        tot=0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            left,right= split(images)\n",
        "            left = Variable(left.cuda())\n",
        "            # print(images.data)\n",
        "            # print(labels)\n",
        "            labels = Variable(labels.cuda())\n",
        "\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(left)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # print(\"hello\")\n",
        "            lossavg +=loss.item()\n",
        "            tot+=1\n",
        "            # if (i+1) % 10 == 0:\n",
        "                # print(\"Epoch [%d/%d], Iter [%d/%d] Loss: %.4f\" %(epoch+1, total_epoch, i+1, len(train_loader), loss.item()))\n",
        "        aver=lossavg/tot\n",
        "        print(\" \")\n",
        "        print(\" \")\n",
        "        print(\" \")\n",
        "        print('the epoch takes time:',time.time()-tims)\n",
        "        print(\"Epoch [%d/%d],  AVERAGELoss: %.4f\" %(epoch+1,total_epoch,aver))\n",
        "        print('evaluate test set:')\n",
        "        acc = test(model, test_loader, btrain=True)\n",
        "        # print(\"acc\",acc)\n",
        "        # print(acc_best)\n",
        "        if acc > acc_best:\n",
        "            acc_best = acc\n",
        "            print('current best acc,', acc_best)\n",
        "            torch.save(model.state_dict(), model_file)\n",
        "        # Decaying Learning Rate\n",
        "        if (epoch+1) / float(total_epoch) == 0.3 or (epoch+1) / float(total_epoch) == 0.6 or (epoch+1) / float(total_epoch) == 0.9:\n",
        "            lr /= 10\n",
        "            print('reset learning rate to:', lr)\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "                print(param_group['lr'])\n",
        "            # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "            # optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
        "    # Save the Model\n",
        "    torch.save(model.state_dict(), 'last_model_92_sgd2_left.pkl')\n",
        "\n",
        "else:\n",
        "    test(model, test_loader, btrain=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c8da62888bdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;31m# Forward + Backward + Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/residual_attention_network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual_block2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_module2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_module2_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual_block3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# print(out.data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/attention_module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_residual_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mout_trunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrunk_branches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mout_mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0mout_softmax1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax1_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_mpool1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mout_skip1_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip1_connection_residual_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_softmax1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    140\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 488\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m max_pool2d = boolean_dispatch(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTh_ZYBDYDXR",
        "colab_type": "code",
        "outputId": "891a2438-9a2a-4a95-c2f4-f9a0b338fdf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "####concat\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from DatasetGenerator import DatasetGenerator\n",
        "# from model.residual_attention_network_pre import ResidualAttentionModel\n",
        "# based https://github.com/liudaizong/Residual-Attention-Network\n",
        "# from residual_attention_network import ResidualAttentionModel_448input as ResidualAttentionModel\n",
        "from residual_attention_network import ResidualAttentionModel_448concat as ResidualAttentionModelconcat\n",
        "\n",
        "model_file = '/content/model_92_sgdconcattest1.pkl'\n",
        "\n",
        "\n",
        "# for test\n",
        "def test(model, test_loader, btrain=False, model_file=model_file):\n",
        "    # Test\n",
        "    if not btrain:\n",
        "        model.load_state_dict(torch.load(model_file))\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    #\n",
        "    class_correct = list(0. for i in range(2))\n",
        "    class_total = list(0. for i in range(2))\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        left,right=split(images)\n",
        "        left = Variable(left.cuda())\n",
        "        right = Variable(right.cuda())\n",
        "        labels = Variable(labels.cuda())\n",
        "        outputs = model(left,right)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.data).sum()\n",
        "        #\n",
        "        c = (predicted == labels.data).squeeze()\n",
        "        # print(labels)\n",
        "        # print(c.shape)\n",
        "        # print(c)\n",
        "        xyz=c.to('cpu').numpy()\n",
        "        # print(\"xyz: \" ,xyz[2])\n",
        "        \n",
        "        for i in range(3):\n",
        "            label = labels.data[i]\n",
        "            # print(c[i])\n",
        "            # abc=c[i][0]\n",
        "            class_correct[label] += xyz[i]\n",
        "            class_total[label] += 1\n",
        "        #     print(xyz[i])\n",
        "        #     print(\"class_correct: \",class_correct)\n",
        "        # print(\"batch end\")\n",
        "\n",
        "    print('Accuracy of the model on the test images: %d %%' % (100 * float(correct) / total))\n",
        "    print('Accuracy of the model on the test images:', float(correct)/total)\n",
        "    for i in range(2):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    return 100*correct / total\n",
        "\n",
        "\n",
        "# Image Preprocessing\n",
        "pathDirData='/content/drive/My Drive/publicbatch/'\n",
        "pathDirDataTest='/content/drive/My Drive/batch1_crop/'\n",
        "# normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "normalize = transforms.Normalize([0.5742, 0.5745, 0.5749], [0.1908, 0.1907, 0.1906])\n",
        "transform = transforms.Compose([\n",
        "    # transforms.RandomRotation(degrees=15),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize((448,896)),   #left, top, right, bottom\n",
        "    # transforms.Scale(224),\n",
        "    transforms.ToTensor()\n",
        "    # normalize\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((448,896)),                                  \n",
        "    transforms.ToTensor()\n",
        "    # normalize\n",
        "])\n",
        "# when image is rgb, totensor do the division 255\n",
        "\n",
        "train_dataset = DatasetGenerator(pathImageDirectory=pathDirData, transform=transform)\n",
        "\n",
        "test_dataset = DatasetGenerator(pathImageDirectory=pathDirDataTest, transform=test_transform)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=6, # 64\n",
        "                                           shuffle=True, num_workers=8)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=3,\n",
        "                                          shuffle=True)\n",
        "\n",
        "classes = ('no Roi','Roi')\n",
        "model = ResidualAttentionModelconcat().cuda()\n",
        "# print(model)\n",
        "\n",
        "lr = 3.00000002e-03 # 0.1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.8, nesterov=True, weight_decay=0.0003)\n",
        "# optimizer = optim.Adam (model.parameters(), lr=lr, betas=(0.8, 0.999), eps=1e-08, weight_decay=0.0001)\n",
        "# scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 4, mode = 'min')\n",
        "is_train = True\n",
        "is_pretrain = False\n",
        "acc_best = 0\n",
        "total_epoch = 40\n",
        "if is_train is True:\n",
        "    if is_pretrain == True:\n",
        "        model.load_state_dict((torch.load(model_file)))\n",
        "    # Training\n",
        "    for epoch in range(total_epoch):\n",
        "        model.train()\n",
        "        tims = time.time()\n",
        "        lossavg=0\n",
        "        tot=0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            left,right= split(images)\n",
        "            left = Variable(left.cuda())\n",
        "            right = Variable(right.cuda())\n",
        "            # print(images.data)\n",
        "            # print(labels)\n",
        "            labels = Variable(labels.cuda())\n",
        "\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(left,right)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # print(\"hello\")\n",
        "            lossavg +=loss.item()\n",
        "            tot+=1\n",
        "            # if (i+1) % 10 == 0:\n",
        "                # print(\"Epoch [%d/%d], Iter [%d/%d] Loss: %.4f\" %(epoch+1, total_epoch, i+1, len(train_loader), loss.item()))\n",
        "        aver=lossavg/tot\n",
        "        print(\" \")\n",
        "        print(\" \")\n",
        "        print(\" \")\n",
        "        print('the epoch takes time:',time.time()-tims)\n",
        "        print(\"Epoch [%d/%d],  AVERAGELoss: %.4f\" %(epoch+1,total_epoch,aver))\n",
        "        print('evaluate test set:')\n",
        "        acc = test(model, test_loader, btrain=True)\n",
        "        # print(\"acc\",acc)\n",
        "        # print(acc_best)\n",
        "        if acc > acc_best:\n",
        "            acc_best = acc\n",
        "            print('current best acc,', acc_best)\n",
        "            torch.save(model.state_dict(), './model_92_sgdconcattest12.pkl')\n",
        "        # Decaying Learning Rate\n",
        "        if (epoch+1) / float(total_epoch) == 0.3 or (epoch+1) / float(total_epoch) == 0.6 or (epoch+1) / float(total_epoch) == 0.9:\n",
        "            lr /= 10\n",
        "            print('reset learning rate to:', lr)\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "                print(param_group['lr'])\n",
        "            # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "            # optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
        "    # Save the Model\n",
        "    torch.save(model.state_dict(), 'last_model_92_sgd2_concattest1.pkl')\n",
        "\n",
        "else:\n",
        "    test(model, test_loader, btrain=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 22.51094651222229\n",
            "Epoch [1/40],  AVERAGELoss: 0.8268\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 68 %\n",
            "Accuracy of the model on the test images: 0.6808510638297872\n",
            "Accuracy of no Roi : 94 %\n",
            "Accuracy of   Roi :  2 %\n",
            "current best acc, tensor(68, device='cuda:0')\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 22.9018976688385\n",
            "Epoch [2/40],  AVERAGELoss: 0.7516\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 28 %\n",
            "Accuracy of the model on the test images: 0.28368794326241137\n",
            "Accuracy of no Roi :  0 %\n",
            "Accuracy of   Roi : 100 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 22.185495138168335\n",
            "Epoch [3/40],  AVERAGELoss: 0.7772\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 24 %\n",
            "Accuracy of the model on the test images: 0.24822695035460993\n",
            "Accuracy of no Roi : 18 %\n",
            "Accuracy of   Roi : 40 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 22.425257444381714\n",
            "Epoch [4/40],  AVERAGELoss: 0.6154\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 42 %\n",
            "Accuracy of the model on the test images: 0.425531914893617\n",
            "Accuracy of no Roi : 40 %\n",
            "Accuracy of   Roi : 47 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 22.50107979774475\n",
            "Epoch [5/40],  AVERAGELoss: 0.6942\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 61 %\n",
            "Accuracy of the model on the test images: 0.6170212765957447\n",
            "Accuracy of no Roi : 79 %\n",
            "Accuracy of   Roi : 17 %\n",
            " \n",
            " \n",
            " \n",
            "the epoch takes time: 22.30952000617981\n",
            "Epoch [6/40],  AVERAGELoss: 0.6353\n",
            "evaluate test set:\n",
            "Accuracy of the model on the test images: 58 %\n",
            "Accuracy of the model on the test images: 0.5886524822695035\n",
            "Accuracy of no Roi : 73 %\n",
            "Accuracy of   Roi : 22 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idPY8uUVJidm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import math \n",
        "def sigmoid(x):\n",
        " \n",
        "  \n",
        " \n",
        "  return 1/(1 + np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w4JGbJHo4ui",
        "colab_type": "code",
        "outputId": "18c998c8-41e8-4064-bc09-19c52f530040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "#######testing\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "# import os\n",
        "import cv2\n",
        "import time\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from DatasetGeneratortest import DatasetGenerator\n",
        "# from model.residual_attention_network_pre import ResidualAttentionModel\n",
        "# based https://github.com/liudaizong/Residual-Attention-Network\n",
        "# from residual_attention_network import ResidualAttentionModel_448input as ResidualAttentionModel\n",
        "from residual_attention_network import ResidualAttentionModel_448concat as ResidualAttentionModelconcat\n",
        "from residual_attention_network import ResidualAttentionModel_448input as ResidualAttentionModel\n",
        "\n",
        "model_file = '/content/drive/My Drive/model_448_sgd_full_lungs_85_without_normalization.pkl'\n",
        "# model_file='/content/model_448_sgd_full_lungs_85_without_normalization.pkl'\n",
        "pathDirDataTest='/content/drive/My Drive/test/'\n",
        "labl=[]\n",
        "out=[]\n",
        "\n",
        "def test(model, test_loader, btrain=False, model_file=model_file):\n",
        "    # Test\n",
        "    if not btrain:\n",
        "        model.load_state_dict(torch.load(model_file))\n",
        "    \n",
        "    # model = nn.Sequential(model,nn.Softmax(dim=1))\n",
        "    # model.fc = nn.Sequential(*list(model.fc) + [nn.Softmax(1)])\n",
        "    model.eval()\n",
        "    # print(model)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    class_noRoi=0\n",
        "    class_roi=0\n",
        "    total_noroi=0\n",
        "    total_roi=0\n",
        "    \n",
        "    #\n",
        "    class_correct = list(0. for i in range(2))\n",
        "    class_total = list(0. for i in range(2))\n",
        "\n",
        "    for images, labels,files in test_loader:\n",
        "        left,right=split(images)\n",
        "        # inp=Variable(images.cuda())\n",
        "        left = Variable(left.cuda())\n",
        "        right = Variable(right.cuda())\n",
        "        labels = Variable(labels.cuda())\n",
        "        outputs = model(left,right)\n",
        "        # outputs=model(inp)\n",
        "        # print(outputs)\n",
        "        # print(files)\n",
        "        # print(labels)\n",
        "        labl.append(labels.to('cpu').numpy())\n",
        "        # out.append([torch.max(i) for i in outputs.to('cpu') ])\n",
        "        out.append(sigmoid(outputs.data.to('cpu').numpy()))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        # out.append(np.argmax(outputs.data.to('cpu').numpy(),axis=1))\n",
        "        # _,prob=torch.max(outputs.data)\n",
        "        # print(torch.max(outputs.data),1)\n",
        "        # print(\"prediction: \",prob)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.data).sum()\n",
        "        #\n",
        "        c = (predicted == labels.data).squeeze()\n",
        "        # print(labels)\n",
        "        # print(c.shape)\n",
        "        # print(c)\n",
        "        # print(c[0])\n",
        "        xyz=c.to('cpu').numpy()\n",
        "        labels=labels.to('cpu').numpy()\n",
        "        \n",
        "        # class_noRoi += (c[0]==True).sum()\n",
        "        for i in range (len(labels)):\n",
        "          if labels[i]==0 and xyz[i]==True:\n",
        "            class_noRoi +=1\n",
        "            \n",
        "          if labels[i]==1 and xyz[i]==True :\n",
        "            class_roi +=1\n",
        "          if labels[i]==0:\n",
        "            total_noroi +=1\n",
        "          if labels[i]==1:\n",
        "            total_roi +=1\n",
        "\n",
        "        # print(\"\")\n",
        "        # xyz=c.to('cpu').numpy()\n",
        "        # # print(\"xyz: \" ,xyz[2])\n",
        "        # # print(\"\")\n",
        "        \n",
        "        # for i in range(1):\n",
        "        #     label = labels.data[i]\n",
        "        #     # print(c[i])\n",
        "        #     # abc=c[i][0]\n",
        "        #     class_correct[label] += xyz[i]\n",
        "        #     class_total[label] += 1\n",
        "        # #     print(xyz[i])\n",
        "        # #     print(\"class_correct: \",class_correct)\n",
        "        # # print(\"batch end\")\n",
        "\n",
        "    \n",
        "    print(\"number of correct prediction for normal lungs: \",class_noRoi)\n",
        "    print(\"number of corret prediction for Covid 19 lungs: \",class_roi)\n",
        "    print(\"total correct: \",correct)\n",
        "    print(\"total test set: \",total)\n",
        "    print(\"total number of normal lungs: \",total_noroi)\n",
        "    print(\"total number of covid19 lungs: \",total_roi)\n",
        "    # print(correct,total)\n",
        "    print('Accuracy of the model on the test images: %d %%' % (100 * float(correct) / total))\n",
        "    print('Accuracy of the model on the test images:', float(correct)/total)\n",
        "    print('Accuracy of the model for class normal lungs: ',100*class_noRoi/total_noroi)\n",
        "    print('Accuracy of the model for class Covid19: ',100*class_roi/total_roi)\n",
        "    data={\"covid-19\":[class_roi,total_noroi-class_noRoi],\"Normal\":[total_roi-class_roi,class_noRoi]}\n",
        "    confusion_matrix= pd.DataFrame(data,index=[\"covid-19\",\"Normal\"])\n",
        "    print(\"\")\n",
        "    print(\"confusion matrix: \")\n",
        "    print(confusion_matrix)\n",
        "    recall=confusion_matrix.iloc[0][0]/(confusion_matrix.iloc[0][0]+confusion_matrix.iloc[0][1])\n",
        "    precision=confusion_matrix.iloc[0][0]/(confusion_matrix.iloc[0][0]+confusion_matrix.iloc[1][0])\n",
        "    print(\"\")\n",
        "    print(\"recall: \", recall)\n",
        "    print(\"precision: \", precision)\n",
        "    # for i in range(2):\n",
        "    #     print('Accuracy of %5s : %2d %%' % (\n",
        "    #         classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    return 100*correct / total\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((448,448)),                                  \n",
        "    transforms.ToTensor()\n",
        "    # normalize\n",
        "])\n",
        "# when image is rgb, totensor do the division 255\n",
        "model=ResidualAttentionModel().cuda()\n",
        "classes = ('no Roi','Roi')\n",
        "\n",
        "test_dataset = DatasetGenerator(pathImageDirectory=pathDirDataTest, transform=test_transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=2,\n",
        "                                          shuffle=False)\n",
        "accuracy=test(model, test_loader, btrain=False)\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of correct prediction for normal lungs:  19\n",
            "number of corret prediction for Covid 19 lungs:  21\n",
            "total correct:  tensor(40, device='cuda:0')\n",
            "total test set:  48\n",
            "total number of normal lungs:  23\n",
            "total number of covid19 lungs:  25\n",
            "Accuracy of the model on the test images: 83 %\n",
            "Accuracy of the model on the test images: 0.8333333333333334\n",
            "Accuracy of the model for class normal lungs:  82.6086956521739\n",
            "Accuracy of the model for class Covid19:  84.0\n",
            "\n",
            "confusion matrix: \n",
            "          covid-19  Normal\n",
            "covid-19        21       4\n",
            "Normal           4      19\n",
            "\n",
            "recall:  0.84\n",
            "precision:  0.84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDKAiua9TeBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "dfdf117c-00d9-4e60-9346-467fded01fb8"
      },
      "source": [
        "#######testing only prediction\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "# import os\n",
        "import cv2\n",
        "import time\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from DatasetGeneratortest import DatasetGenerator\n",
        "from torchsummary import summary\n",
        "# from model.residual_attention_network_pre import ResidualAttentionModel\n",
        "# based https://github.com/liudaizong/Residual-Attention-Network\n",
        "# from residual_attention_network import ResidualAttentionModel_448input as ResidualAttentionModel\n",
        "from residual_attention_network import ResidualAttentionModel_448concat as ResidualAttentionModelconcat\n",
        "from residual_attention_network import ResidualAttentionModel_448input as ResidualAttentionModel\n",
        "\n",
        "model_file = '/content/drive/My Drive/model_92_sgdconcatupdate89.pkl'\n",
        "# model_file='/content/model_448_sgd_full_lungs_85_without_normalization.pkl'\n",
        "pathDirDataTest='/content/drive/My Drive/test/'\n",
        "labl=[]\n",
        "out=[]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def test(model, test_loader, btrain=False, model_file=model_file):\n",
        "    # Test\n",
        "    if not btrain:\n",
        "        model.load_state_dict(torch.load(model_file))\n",
        "    \n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for images, labels,files in test_loader:\n",
        "        \n",
        "        left,right=split(images)\n",
        "        # inp=Variable(images.cuda())\n",
        "        left = Variable(left.to(device))\n",
        "        # print(left.shape)\n",
        "        right = Variable(right.to(device))\n",
        "        # labels = Variable(labels.to(device))\n",
        "        outputs = model(left,right)\n",
        "        out.append([files,sigmoid(outputs.data.to('cpu').numpy())])\n",
        "        \n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((448,896)),                                  \n",
        "    transforms.ToTensor()\n",
        "    # normalize\n",
        "])\n",
        "# when image is rgb, totensor do the division 255\n",
        "model=ResidualAttentionModelconcat().to(device)\n",
        "# classes = ('no Roi','Roi')\n",
        "# print(summary(model, [(1,3, 16, 16), (1,3, 28, 28)]))\n",
        "\n",
        "test_dataset = DatasetGenerator(pathImageDirectory=pathDirDataTest, transform=test_transform)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=1,\n",
        "                                          shuffle=False)\n",
        "test(model, test_loader, btrain=False)\n",
        "\n",
        "probabilty=[]\n",
        "filename=[]\n",
        "\n",
        "for i in range(len(out)):\n",
        "  probabilty.append(out[i][1][0][1])\n",
        "  filename.append(out[i][0][0])\n",
        "\n",
        "output=pd.DataFrame()\n",
        "output['filename']=filename\n",
        "output['Probabilty']=probabilty\n",
        "print(output)\n",
        "\n",
        "  "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   filename  Probabilty\n",
            "0           10000988652.png    0.444872\n",
            "1           10000988731.png    0.314858\n",
            "2           10000988732.png    0.284012\n",
            "3           10000988827.png    0.487903\n",
            "4           10000988828.png    0.297800\n",
            "5           10000988834.png    0.230281\n",
            "6           10000988865.png    0.227218\n",
            "7           10000988908.png    0.228421\n",
            "8           10000988928.png    0.542734\n",
            "9           10000988941.png    0.470829\n",
            "10          10000989034.png    0.395668\n",
            "11          10001012121.png    0.138616\n",
            "12          10001012125.png    0.313190\n",
            "13          10001012335.png    0.248574\n",
            "14          10001018450.png    0.492248\n",
            "15          10001020995.png    0.428434\n",
            "16          10001028537.png    0.103729\n",
            "17          10001028568.png    0.284005\n",
            "18          10000988599.png    0.530840\n",
            "19          10001030075.png    0.150439\n",
            "20          10001030683.png    0.358903\n",
            "21          10001030928.png    0.211341\n",
            "22          10001030997.png    0.098118\n",
            "23          10001012526.png    0.235015\n",
            "24          10001014483.png    0.235423\n",
            "25          10001014621.png    0.354065\n",
            "26          10001016313.png    0.707511\n",
            "27  10001016313_rotated.png    0.820045\n",
            "28          10001026284.png    0.835684\n",
            "29    10001026284rotate.png    0.784169\n",
            "30          10001026984.png    0.582174\n",
            "31    10001026984rotate.png    0.667478\n",
            "32          10001027568.png    0.615815\n",
            "33          10001028491.png    0.601624\n",
            "34  10001028491_rotated.png    0.654506\n",
            "35          10001028528.png    0.726864\n",
            "36          10001028725.png    0.607986\n",
            "37   10001028725rotated.png    0.718680\n",
            "38          10001028994.png    0.519377\n",
            "39  10001028994_rotated.png    0.571656\n",
            "40          10001029092.png    0.659881\n",
            "41  10001029092_rotated.png    0.849897\n",
            "42          10001022751.png    0.518960\n",
            "43          10001022905.png    0.681544\n",
            "44          10001023072.png    0.754173\n",
            "45          10001023079.png    0.690636\n",
            "46          10001023684.png    0.721938\n",
            "47          10001023712.png    0.671766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NhQn1xcbrT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "167665c9-0ee8-4a5e-f2ba-cccfaeff4d31"
      },
      "source": [
        "probabilty=[]\n",
        "filename=[]\n",
        "# print(out[1][0])\n",
        "for i in range(len(out)):\n",
        "  probabilty.append(out[i][1][0][1])\n",
        "  filename.append(out[i][0][0])\n",
        "\n",
        "# print(probabilty)\n",
        "# print(filename)\n",
        "\n",
        "output=pd.DataFrame()\n",
        "output['filename']=filename\n",
        "output['Probabilty']=probabilty\n",
        "print(output)\n",
        "\n",
        "# for i in range(len(out)):\n",
        "#   if i==0:\n",
        "#     output=pd.DataFrame([[out[i][0][0]],[out[i][1][0][1]]],columns=['filename','Probabilty'])\n",
        "#   else:\n",
        "#     output1=pd.DataFrame([[out[i][0][0]],[out[i][1][0][1]]],columns=['filename','Probabilty'])\n",
        "#     output.append(output1)\n",
        "# print(output)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('10000988731.png',)\n",
            "                   filename  Probabilty\n",
            "0           10000988652.png    0.444872\n",
            "1           10000988731.png    0.314858\n",
            "2           10000988732.png    0.284012\n",
            "3           10000988827.png    0.487903\n",
            "4           10000988828.png    0.297800\n",
            "5           10000988834.png    0.230281\n",
            "6           10000988865.png    0.227218\n",
            "7           10000988908.png    0.228421\n",
            "8           10000988928.png    0.542734\n",
            "9           10000988941.png    0.470829\n",
            "10          10000989034.png    0.395668\n",
            "11          10001012121.png    0.138616\n",
            "12          10001012125.png    0.313190\n",
            "13          10001012335.png    0.248574\n",
            "14          10001018450.png    0.492248\n",
            "15          10001020995.png    0.428434\n",
            "16          10001028537.png    0.103729\n",
            "17          10001028568.png    0.284005\n",
            "18          10000988599.png    0.530840\n",
            "19          10001030075.png    0.150439\n",
            "20          10001030683.png    0.358903\n",
            "21          10001030928.png    0.211341\n",
            "22          10001030997.png    0.098118\n",
            "23          10001012526.png    0.235015\n",
            "24          10001014483.png    0.235423\n",
            "25          10001014621.png    0.354065\n",
            "26          10001016313.png    0.707511\n",
            "27  10001016313_rotated.png    0.820045\n",
            "28          10001026284.png    0.835684\n",
            "29    10001026284rotate.png    0.784169\n",
            "30          10001026984.png    0.582174\n",
            "31    10001026984rotate.png    0.667478\n",
            "32          10001027568.png    0.615815\n",
            "33          10001028491.png    0.601624\n",
            "34  10001028491_rotated.png    0.654506\n",
            "35          10001028528.png    0.726864\n",
            "36          10001028725.png    0.607986\n",
            "37   10001028725rotated.png    0.718680\n",
            "38          10001028994.png    0.519377\n",
            "39  10001028994_rotated.png    0.571656\n",
            "40          10001029092.png    0.659881\n",
            "41  10001029092_rotated.png    0.849897\n",
            "42          10001022751.png    0.518960\n",
            "43          10001022905.png    0.681544\n",
            "44          10001023072.png    0.754173\n",
            "45          10001023079.png    0.690636\n",
            "46          10001023684.png    0.721938\n",
            "47          10001023712.png    0.671766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtzHRxL8Jz_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "b9fa074c-f778-4a7f-cc96-167565fb2f8c"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# print(labl)\n",
        "# print(out)\n",
        "import sklearn.metrics as sk\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "lablarray=[]\n",
        "outarray=[]\n",
        "\n",
        "# print(out)\n",
        "# print(out[0][:,1])\n",
        "\n",
        "for i in range(len(out)):\n",
        "  outarray.append(out[i][:,1])\n",
        "\n",
        "npout=np.array(outarray).ravel()\n",
        "print(npout)\n",
        "prediction_binary = np.where(npout > 0.60,1,0)\n",
        "print(prediction_binary)\n",
        "\n",
        "for i in labl:\n",
        "  lablarray.append(i[0])\n",
        "  lablarray.append(i[1])\n",
        "  # lablarray.append(i[2])\n",
        "  \n",
        "# # sk.roc_curve(labl,out)\n",
        "# print(lablarray)\n",
        "# count=0\n",
        "\n",
        "# # scaler = StandardScaler()\n",
        "# # out1=scaler.fit(out)\n",
        "\n",
        "# # print(out)\n",
        "# # print(out1)\n",
        "# # outarray=np.array(out).ravel()\n",
        "# # out1=np.asarray(outarray)\n",
        "# for i in out:\n",
        "#   # print(count)\n",
        "#   for a in i:\n",
        "    \n",
        "#     if lablarray[count]==0:\n",
        "#       outarray.append(a[0])\n",
        "#     else:\n",
        "#       outarray.append(a[1])\n",
        "\n",
        "#     count +=1\n",
        "# # xyz=outarray.append(lablarray)\n",
        "# print(outarray)\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "nclass=2 \n",
        "\n",
        "fpr, tpr, th = sk.roc_curve(np.array(lablarray), prediction_binary)\n",
        "roc_auc = sk.auc(fpr, tpr)\n",
        "# print(fpr) \n",
        "# print(tpr)\n",
        "# print(th)\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('full lung')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.29151356 0.71211714 0.45469657 0.18688327 0.11924458 0.08178023\n",
            " 0.00974939 0.12911803 0.7636067  0.22408707 0.4347057  0.10239009\n",
            " 0.25108653 0.20322922 0.44737294 0.3734981  0.04010245 0.11122385\n",
            " 0.91901964 0.20861468 0.6522157  0.21951751 0.20511676 0.57173616\n",
            " 0.7211615  0.17302091 0.6859016  0.7562162  0.89573705 0.8510159\n",
            " 0.5142426  0.24854524 0.5551962  0.3042815  0.30057132 0.987884\n",
            " 0.96658474 0.9007112  0.5087362  0.5703403  0.86284333 0.7755713\n",
            " 0.5073515  0.89320654 0.7236826  0.8655857  0.8694781  0.7780309 ]\n",
            "[0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 1\n",
            " 1 0 0 1 1 0 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfw6MV8lo_ua",
        "colab_type": "code",
        "outputId": "ec821b3b-060d-43d4-be4b-7f4f4c971e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Mar 19 10:49:54 2020\n",
        "\n",
        "@author: sidhant\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import sys\n",
        "from PIL import Image\n",
        "\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# from DensenetModels import DenseNet121\n",
        "# from DensenetModels import DenseNet169\n",
        "# from DensenetModels import DenseNet201\n",
        "# from residual_attention_network import ResidualAttentionModel_448concat as ResidualAttentionModelconcat\n",
        "from residual_attention_network import ResidualAttentionModel_448input as ResidualAttentionModel\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "#-------------------------------------------------------------------------------- \n",
        "#---- Class to generate heatmaps (CAM)\n",
        "\n",
        "class HeatmapGenerator ():\n",
        "    \n",
        "    #---- Initialize heatmap generator\n",
        "    #---- pathModel - path to the trained densenet model\n",
        "    #---- nnArchitecture - architecture name DENSE-NET121, DENSE-NET169, DENSE-NET201\n",
        "    #---- nnClassCount - class count, 14 for chxray-14\n",
        "\n",
        " \n",
        "    def __init__ (self, pathModel,nnClassCount, transCrop):\n",
        "       \n",
        "        #---- Initialize the network\n",
        "        # if nnArchitecture == 'DENSE-NET-121': model = DenseNet121(nnClassCount, True).cuda()\n",
        "        # elif nnArchitecture == 'DENSE-NET-169': model = DenseNet169(nnClassCount, True).cuda()\n",
        "        # elif nnArchitecture == 'DENSE-NET-201': model = DenseNet201(nnClassCount, True).cuda()\n",
        "        # model = ResidualAttentionModel()\n",
        "          \n",
        "        # model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "        # modelCheckpoint = torch.load(pathModel)\n",
        "        # model.load_state_dict(modelCheckpoint['state_dict'])\n",
        "\n",
        "        # self.model = model.module.densenet121.features\n",
        "        model = ResidualAttentionModel().cuda()\n",
        "        # model=model.cuda()\n",
        "        # print(model.features)\n",
        "\n",
        "        # modelCheckpoint = torch.load(pathModel)\n",
        "        # print(modelCheckpoint['state_dict'])\n",
        "        \n",
        "        model.load_state_dict((torch.load(pathModel)))\n",
        "        \n",
        "        # print(model)\n",
        "        # model.mpool2=Identity()\n",
        "        # model.fc=Identity()\n",
        "        # print(model)\n",
        "\n",
        "        \n",
        "\n",
        "        self.model = model \n",
        "        print(self.model)\n",
        "        self.model.eval()\n",
        "        \n",
        "        #---- Initialize the weights\n",
        "        \n",
        "        \n",
        "        print(list(self.model.residual_block6.conv4.parameters()))\n",
        "        # print(list(self.model.parameters()))\n",
        "        self.weights = list(self.model.mpool2[0].parameters())\n",
        "\n",
        "        #---- Initialize the image transform - resize + normalize\n",
        "        # normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        transformList = []\n",
        "        transformList.append(transforms.Resize((448,448)))\n",
        "        transformList.append(transforms.ToTensor())\n",
        "        # transformList.append(normalize)      \n",
        "        \n",
        "        self.transformSequence = transforms.Compose(transformList)\n",
        "    \n",
        "    #--------------------------------------------------------------------------------\n",
        "     \n",
        "    def generate (self, pathImageFile, pathOutputFile, transCrop):\n",
        "        \n",
        "        #---- Load image, transform, convert \n",
        "        imageData = Image.open(pathImageFile).convert('RGB')\n",
        "        imageData = self.transformSequence(imageData)\n",
        "        imageData = imageData.unsqueeze_(0)\n",
        "        # left,right=split(imageData)\n",
        "        \n",
        "        # leftlung = torch.autograd.Variable(left)\n",
        "        # rightlung = torch.autograd.Variable(right)\n",
        "        input = torch.autograd.Variable(imageData)\n",
        "        \n",
        "        self.model.cuda()\n",
        "        output = self.model(input.cuda())\n",
        "        # print(output.shape)\n",
        "        # print(self.weights)\n",
        "        #---- Generate heatmap\n",
        "        heatmap = None\n",
        "        for i in range (0, len(self.weights)):\n",
        "            map = output[0,i]\n",
        "            if i == 0: heatmap = self.weights[i] * map\n",
        "            else: heatmap += self.weights[i] * map\n",
        "        \n",
        "        #---- Blend original and heatmap \n",
        "        print(heatmap)\n",
        "        npHeatmap = heatmap.cpu().data.numpy()\n",
        "        print(np.max(npHeatmap))\n",
        "\n",
        "        imgOriginal = cv2.imread(pathImageFile, 1)\n",
        "        imgOriginal = cv2.resize(imgOriginal, (448, 448))\n",
        "        \n",
        "        cam = npHeatmap / np.max(npHeatmap)\n",
        "        print(cam)\n",
        "        # cam = np.squeeze(cam) \n",
        "        # plt.imshow(cam)\n",
        "        \n",
        "        cam = cv2.resize(cam, (transCrop, transCrop))\n",
        "        heatmap = cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET)\n",
        "        # heatmap=cv2.resize(heatmap,(transCrop, transCrop))      \n",
        "        img = heatmap * 0.5 + imgOriginal\n",
        "            \n",
        "        cv2.imwrite(pathOutputFile, img)\n",
        "        return img\n",
        "        \n",
        "#-------------------------------------------------------------------------------- \n",
        "\n",
        "pathInputImage = \"/content/drive/My Drive/cropped_images_new/10000984160.png\"\n",
        "pathOutputImage = '/content/drive/My Drive/heatmap.png'\n",
        "pathModel = \"/content/model_448_sgd_full_lungs_85_without_normalization.pkl\"\n",
        "\n",
        "nnArchitecture = ' '\n",
        "nnClassCount = 2\n",
        "\n",
        "transCrop = 448\n",
        "# test_dataset = DatasetGenerator(pathImageDirectory=pathDirDataTest, transform=test_transform)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "#                                           batch_size=2,\n",
        "#                                           shuffle=False)\n",
        "\n",
        "\n",
        "h = HeatmapGenerator(pathModel,nnClassCount, transCrop)\n",
        "heatimg=h.generate(pathInputImage, pathOutputImage, transCrop)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResidualAttentionModel_448input(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (residual_block0): ResidualBlock(\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (conv4): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  )\n",
            "  (attention_module0): AttentionModule_stage0(\n",
            "    (first_residual_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (trunk_branches): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax1_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (skip1_connection_residual_block): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax2_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (skip2_connection_residual_block): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax3_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (skip3_connection_residual_block): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mpool4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax4_blocks): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (interpolation4): UpsamplingBilinear2d(size=(14, 14), mode=bilinear)\n",
            "    (softmax5_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (interpolation3): UpsamplingBilinear2d(size=(28, 28), mode=bilinear)\n",
            "    (softmax6_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (interpolation2): UpsamplingBilinear2d(size=(56, 56), mode=bilinear)\n",
            "    (softmax7_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (interpolation1): UpsamplingBilinear2d(size=(112, 112), mode=bilinear)\n",
            "    (softmax8_blocks): Sequential(\n",
            "      (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (6): Sigmoid()\n",
            "    )\n",
            "    (last_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (residual_block1): ResidualBlock(\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (conv4): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  )\n",
            "  (attention_module1): AttentionModule_stage1(\n",
            "    (first_residual_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (trunk_branches): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax1_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (skip1_connection_residual_block): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax2_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (skip2_connection_residual_block): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mpool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax3_blocks): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (interpolation3): UpsamplingBilinear2d(size=(14, 14), mode=bilinear)\n",
            "    (softmax4_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (interpolation2): UpsamplingBilinear2d(size=(28, 28), mode=bilinear)\n",
            "    (softmax5_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (interpolation1): UpsamplingBilinear2d(size=(56, 56), mode=bilinear)\n",
            "    (softmax6_blocks): Sequential(\n",
            "      (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (6): Sigmoid()\n",
            "    )\n",
            "    (last_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (residual_block2): ResidualBlock(\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (conv4): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  )\n",
            "  (attention_module2): AttentionModule_stage2(\n",
            "    (first_residual_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (trunk_branches): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax1_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (skip1_connection_residual_block): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax2_blocks): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (interpolation2): UpsamplingBilinear2d(size=(14, 14), mode=bilinear)\n",
            "    (softmax3_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (interpolation1): UpsamplingBilinear2d(size=(28, 28), mode=bilinear)\n",
            "    (softmax4_blocks): Sequential(\n",
            "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (6): Sigmoid()\n",
            "    )\n",
            "    (last_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (attention_module2_2): AttentionModule_stage2(\n",
            "    (first_residual_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (trunk_branches): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax1_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (skip1_connection_residual_block): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mpool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax2_blocks): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (interpolation2): UpsamplingBilinear2d(size=(14, 14), mode=bilinear)\n",
            "    (softmax3_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (interpolation1): UpsamplingBilinear2d(size=(28, 28), mode=bilinear)\n",
            "    (softmax4_blocks): Sequential(\n",
            "      (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (6): Sigmoid()\n",
            "    )\n",
            "    (last_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (residual_block3): ResidualBlock(\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (conv4): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  )\n",
            "  (attention_module3): AttentionModule_stage3(\n",
            "    (first_residual_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (trunk_branches): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax1_blocks): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (interpolation1): UpsamplingBilinear2d(size=(14, 14), mode=bilinear)\n",
            "    (softmax2_blocks): Sequential(\n",
            "      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (6): Sigmoid()\n",
            "    )\n",
            "    (last_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (attention_module3_2): AttentionModule_stage3(\n",
            "    (first_residual_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (trunk_branches): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax1_blocks): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (interpolation1): UpsamplingBilinear2d(size=(14, 14), mode=bilinear)\n",
            "    (softmax2_blocks): Sequential(\n",
            "      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (6): Sigmoid()\n",
            "    )\n",
            "    (last_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (attention_module3_3): AttentionModule_stage3(\n",
            "    (first_residual_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (trunk_branches): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (mpool1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (softmax1_blocks): Sequential(\n",
            "      (0): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (1): ResidualBlock(\n",
            "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (interpolation1): UpsamplingBilinear2d(size=(14, 14), mode=bilinear)\n",
            "    (softmax2_blocks): Sequential(\n",
            "      (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (6): Sigmoid()\n",
            "    )\n",
            "    (last_blocks): ResidualBlock(\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (conv4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (residual_block4): ResidualBlock(\n",
            "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (conv4): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  )\n",
            "  (residual_block5): ResidualBlock(\n",
            "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (conv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  )\n",
            "  (residual_block6): ResidualBlock(\n",
            "    (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (conv4): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  )\n",
            "  (mpool2): Sequential(\n",
            "    (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
            "  )\n",
            "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n",
            "[Parameter containing:\n",
            "tensor([[[[-0.0214]],\n",
            "\n",
            "         [[-0.0046]],\n",
            "\n",
            "         [[-0.0119]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0122]],\n",
            "\n",
            "         [[ 0.0146]],\n",
            "\n",
            "         [[ 0.0165]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0171]],\n",
            "\n",
            "         [[-0.0057]],\n",
            "\n",
            "         [[-0.0042]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0111]],\n",
            "\n",
            "         [[-0.0011]],\n",
            "\n",
            "         [[-0.0163]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0179]],\n",
            "\n",
            "         [[ 0.0161]],\n",
            "\n",
            "         [[ 0.0118]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0159]],\n",
            "\n",
            "         [[ 0.0177]],\n",
            "\n",
            "         [[ 0.0097]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0160]],\n",
            "\n",
            "         [[-0.0060]],\n",
            "\n",
            "         [[-0.0121]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0162]],\n",
            "\n",
            "         [[ 0.0165]],\n",
            "\n",
            "         [[ 0.0141]]],\n",
            "\n",
            "\n",
            "        [[[-0.0059]],\n",
            "\n",
            "         [[ 0.0215]],\n",
            "\n",
            "         [[-0.0143]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0070]],\n",
            "\n",
            "         [[-0.0117]],\n",
            "\n",
            "         [[ 0.0007]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0174]],\n",
            "\n",
            "         [[-0.0103]],\n",
            "\n",
            "         [[ 0.0087]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0071]],\n",
            "\n",
            "         [[-0.0204]],\n",
            "\n",
            "         [[-0.0218]]]], device='cuda:0', requires_grad=True)]\n",
            "tensor([-2.9030, -2.9011, -2.9009,  ..., -2.9011, -2.9006, -2.9014],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n",
            "-2.8987148\n",
            "[1.0014769 1.0008359 1.0007586 ... 1.0008084 1.0006565 1.0009114]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMfWHLKGdVA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torchvision.models import vgg19\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from residual_attention_network import ResidualAttentionModel_92 as ResidualAttentionModel\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.model = ResidualAttentionModel().cuda()\n",
        "        self.model.load_state_dict((torch.load(\"/content/drive/My Drive/model_92_sgdconcatupdate89.pkl\")))\n",
        "\n",
        "        # self.poollayer=self.model.mpool2\n",
        "        self.classifier=self.model.fc\n",
        "        # self.model.mpool2=Identity()\n",
        "        self.model.fc=Identity()\n",
        "\n",
        "        self.features_conv = self.model\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        # placeholder for the gradients\n",
        "        self.gradients = None\n",
        "    \n",
        "    # hook for the gradients of the activations\n",
        "    def activations_hook(self, grad):\n",
        "        self.gradients = grad\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features_conv(x)\n",
        "        \n",
        "        # register the hook\n",
        "        h = x.register_hook(self.activations_hook)\n",
        "        print(x.size())\n",
        "        \n",
        "        # don't forget the pooling\n",
        "        # x = self.poollayer(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "    \n",
        "    def get_activations_gradient(self):\n",
        "        return self.gradients\n",
        "    \n",
        "    def get_activations(self, x):\n",
        "        return self.features_conv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eeCRKmIhCD1",
        "colab_type": "code",
        "outputId": "00e07506-9083-475b-e033-a2ed58f867f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "from PIL import Image\n",
        "net = Net().cuda()\n",
        "# print(net)\n",
        "\n",
        "# set the evaluation mode\n",
        "net.eval()\n",
        "\n",
        "pathImageFile=\"/content/drive/My Drive/cropped_images_new/10000984160.png\"\n",
        "\n",
        "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "transformList = []\n",
        "transformList.append(transforms.Resize((224,224)))\n",
        "transformList.append(transforms.ToTensor())\n",
        "transformList.append(normalize)      \n",
        "\n",
        "transformSequence = transforms.Compose(transformList)\n",
        "\n",
        "\n",
        "imageData = Image.open(pathImageFile).convert('RGB')\n",
        "imageData = transformSequence(imageData)\n",
        "imageData = imageData.unsqueeze_(0)\n",
        "# input = torch.autograd.Variable(imageData)\n",
        "\n",
        "\n",
        "# get the most likely prediction of the model\n",
        "pred = net(imageData.cuda())\n",
        "\n",
        "print(pred)\n",
        "\n",
        "pred[:,1].backward()\n",
        "\n",
        "# pull the gradients out of the model\n",
        "gradients = net.get_activations_gradient()\n",
        "print(gradients)\n",
        "\n",
        "# pool the gradients across the channels\n",
        "pooled_gradients = torch.mean(gradients, dim=[0,2,3])\n",
        "pooled_gradient=pooled_gradients.to('cpu').numpy()\n",
        "# get the activations of the last convolutional layer\n",
        "activations = net.get_activations(imageData.cuda()).detach()\n",
        "activation=activations.to('cpu').numpy()\n",
        "# print(pooled_gradients)\n",
        "# weight the channels by corresponding gradients\n",
        "for i in range(2048):\n",
        "    # print(i)\n",
        "    activation[0][i] *= pooled_gradient[i]\n",
        "    \n",
        "# average the channels of the activations\n",
        "print(activation)\n",
        "# heatmap = torch.mean(torch.tensor(activation), dim=1).squeeze()\n",
        "heatmap=torch.tensor(activation)\n",
        "\n",
        "# relu on top of the heatmap\n",
        "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
        "# heatmap = np.maximum(heatmap, 0)\n",
        "\n",
        "# normalize the heatmap\n",
        "heatmap /= torch.max(heatmap)\n",
        "print(heatmap)\n",
        "# draw the heatmap\n",
        "plt.matshow(heatmap)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2048])\n",
            "tensor([[-1.0886,  1.4256]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0214,  0.0173, -0.0232,  ..., -0.0118,  0.0070,  0.0067]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-12c84a301ee6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# pool the gradients across the channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mpooled_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mpooled_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooled_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# get the activations of the last convolutional layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
          ]
        }
      ]
    }
  ]
}